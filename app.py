import streamlit as st
import os
import requests
import wikipediaapi
from googleapiclient.discovery import build
import json
import time
import shutil # í´ë” ì••ì¶•ìš©
import base64

# ==========================================
# [ì„¤ì •] ğŸ”‘ API í‚¤ (ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”)
# ==========================================
# ìŠ¤íŠ¸ë¦¼ë¦¿ì˜ ë¹„ë°€ ê¸ˆê³ (secrets)ì—ì„œ í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
# ë§Œì•½ ê¸ˆê³ ì— í‚¤ê°€ ì—†ìœ¼ë©´(ë‚´ PCì—ì„œ ëŒë¦´ ë•Œ), ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ë¹ˆ ë¬¸ìì—´ì„ ë„£ìŠµë‹ˆë‹¤.
if "GOOGLE_API_KEY" in st.secrets:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    GOOGLE_SEARCH_ENGINE_ID = st.secrets["GOOGLE_SEARCH_ENGINE_ID"]
    EMUSEUM_API_KEY = st.secrets["EMUSEUM_API_KEY"]
else:
    # ë‚´ PCì—ì„œ í…ŒìŠ¤íŠ¸í•  ë•Œë¥¼ ìœ„í•´ ê¸°ì¡´ í‚¤ë¥¼ ì—¬ê¸°ì— ì ì–´ë‘˜ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    # í•˜ì§€ë§Œ ë°°í¬í•  ë•ŒëŠ” ì´ ë¶€ë¶„ì„ ë¹„ì›Œë‘ê±°ë‚˜ ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤.
    GOOGLE_API_KEY = "ì—¬ê¸°ì—_ì›ë˜_í‚¤ë¥¼_ì ì–´ë„_ë˜ì§€ë§Œ_ì¶”ì²œí•˜ì§€_ì•ŠìŒ"
    GOOGLE_SEARCH_ENGINE_ID = "ì—¬ê¸°ì—_ì›ë˜_í‚¤"
    EMUSEUM_API_KEY = "ì—¬ê¸°ì—_ì›ë˜_í‚¤"
    
# [ì„¤ì •] ê²€ìƒ‰ ìˆ˜ëŸ‰
COUNT_WIKIMEDIA = 10
COUNT_THE_MET = 5
COUNT_GOOGLE = 3

# ==========================================
# [ê¸°ëŠ¥] Streamlit ì „ìš© í•¨ìˆ˜ë“¤
# ==========================================
def create_temp_folder(folder_name):
    if not os.path.exists(folder_name):
        os.makedirs(folder_name)
    # ê¸°ì¡´ íŒŒì¼ ì‚­ì œ (ê¹¨ë—í•œ ì‹œì‘)
    for filename in os.listdir(folder_name):
        file_path = os.path.join(folder_name, filename)
        try:
            if os.path.isfile(file_path): os.unlink(file_path)
        except: pass

def save_text_file(folder_name, filename, content):
    with open(os.path.join(folder_name, filename), "w", encoding="utf-8") as f:
        f.write(content)

# ==========================================
# [ìˆ˜ì •] í™•ì¥ì ìë™ ë³´ì • ë‹¤ìš´ë¡œë”
# ==========================================
def download_image(url, folder_name, filename, source_list, visited_urls):
    # 1. ì¤‘ë³µ ë° URL ìœ íš¨ì„± ì²´í¬
    if url in visited_urls: return False
    if not url.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp')): return False

    # [í•µì‹¬ ìˆ˜ì •] íŒŒì¼ëª…ì— í™•ì¥ì(.jpg ë“±)ê°€ ì—†ìœ¼ë©´ ê°•ì œë¡œ ë¶™ì—¬ì¤ë‹ˆë‹¤!
    if not filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp')):
        filename += ".jpg"

    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(url, headers=headers, timeout=5)
        if response.status_code == 200:
            path = os.path.join(folder_name, filename)
            with open(path, 'wb') as f: f.write(response.content)
            
            source_list.append(f"[{filename}] : {url}")
            visited_urls.add(url)
            return True
    except: pass
    return False

def get_english_name_from_wiki(korean_name):
    wiki = wikipediaapi.Wikipedia(user_agent='HistoryApp/1.0', language='ko')
    page = wiki.page(korean_name)
    if page.exists() and 'en' in page.langlinks:
        return page.langlinks['en'].title
    return None

# ==========================================
# [ê²€ìƒ‰ ì†ŒìŠ¤ í•¨ìˆ˜ë“¤] (ê¸°ì¡´ ë¡œì§ ë™ì¼, print ëŒ€ì‹  st.write ì‚¬ìš© ì•ˆí•¨)
# ==========================================
def run_search_logic(name, folder_name, use_met, use_google, progress_bar):
    visited_urls = set()
    source_list = []
    
    # 1. ìœ„í‚¤ë°±ê³¼
    progress_bar.progress(10, text="ğŸ“– ìœ„í‚¤ë°±ê³¼ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    wiki = wikipediaapi.Wikipedia(user_agent='HistoryApp/1.0', language='ko')
    page = wiki.page(name)
    if page.exists():
        content = f"ì¸ë¬¼: {name}\nURL: {page.fullurl}\n\n{page.text}"
        save_text_file(folder_name, f"01_{name}_ìƒì„¸ì •ë³´.txt", content)

    # 2. ì˜ë¬¸ëª… íƒìƒ‰
    progress_bar.progress(20, text="ğŸ”¤ ì˜ë¬¸ ì´ë¦„ ë³€í™˜ ì¤‘...")
    english_name = get_english_name_from_wiki(name)
    search_name_global = english_name if english_name else name
    
    # 3. ìœ„í‚¤ë¯¸ë””ì–´
    progress_bar.progress(30, text="ğŸŒ ìœ„í‚¤ë¯¸ë””ì–´ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
    url = "https://commons.wikimedia.org/w/api.php"
    params = {
        "action": "query", "format": "json", "generator": "search",
        "gsrsearch": f"File:{search_name_global}", "gsrnamespace": 6, 
        "gsrlimit": COUNT_WIKIMEDIA, "prop": "imageinfo", "iiprop": "url"
    }
    try:
        res = requests.get(url, params=params, headers={'User-Agent': 'Bot/App'}).json()
        if "query" in res:
            for page_id in res["query"]["pages"]:
                item = res["query"]["pages"][page_id]
                if "imageinfo" in item:
                    img_url = item["imageinfo"][0]["url"]
                    title = item['title'].replace("File:", "").replace(" ", "_")[:20]
                    safe = "".join(c for c in title if c.isalnum() or c in ('_','.'))
                    download_image(img_url, folder_name, f"Wiki_{safe}", source_list, visited_urls)
    except: pass

    # 4. eë®¤ì§€ì—„
    if EMUSEUM_API_KEY and "ì—¬ê¸°ì—" not in EMUSEUM_API_KEY:
        progress_bar.progress(50, text="ğŸº eë®¤ì§€ì—„ ìœ ë¬¼ ê²€ìƒ‰ ì¤‘...")
        base_url = "http://www.emuseum.go.kr/openapi/relic/list"
        request_url = f"{base_url}?serviceKey={EMUSEUM_API_KEY}&name={name}&numOfRows=10"
        try:
            res = requests.get(request_url).json()
            items = res.get('list', [])
            info_text = ""
            for i, item in enumerate(items):
                title = item.get('name', 'ë¬´ì œ')
                desc = item.get('desc', 'ì„¤ëª… ì—†ìŒ')
                info_text += f"[{i+1}] {title} : {desc}\n"
                if item.get('imgUrl'):
                    img = "http://www.emuseum.go.kr" + item['imgUrl'] if not item['imgUrl'].startswith('http') else item['imgUrl']
                    safe = "".join(c for c in title if c.isalnum())[:10]
                    download_image(img, folder_name, f"eMuseum_{i}_{safe}.jpg", source_list, visited_urls)
            if info_text: save_text_file(folder_name, f"02_{name}_eë®¤ì§€ì—„.txt", info_text)
        except: pass

    # 5. ë©”íŠ¸ë¡œí´ë¦¬íƒ„ (ì„ íƒ)
    if use_met:
        progress_bar.progress(70, text="ğŸ›ï¸ ë©”íŠ¸ë¡œí´ë¦¬íƒ„ ë¯¸ìˆ ê´€ ê²€ìƒ‰ ì¤‘...")
        q_name = english_name if english_name else name
        try:
            res = requests.get("https://collectionapi.metmuseum.org/public/collection/v1/search", 
                               params={"q": q_name, "hasImages": "true", "isOnView": "true"}).json()
            ids = res.get('objectIDs', [])
            count = 0
            for obj_id in ids:
                if count >= COUNT_THE_MET: break
                try:
                    item = requests.get(f"https://collectionapi.metmuseum.org/public/collection/v1/objects/{obj_id}").json()
                    img_url = item.get('primaryImage')
                    if img_url and img_url not in visited_urls:
                        title = "".join(c for c in item.get('title','T') if c.isalnum())[:10]
                        if download_image(img_url, folder_name, f"Met_{obj_id}_{title}.jpg", source_list, visited_urls):
                            count += 1
                except: continue
        except: pass

    # 6. êµ¬ê¸€ (ì„ íƒ)
    if use_google and GOOGLE_API_KEY and "ì—¬ê¸°ì—" not in GOOGLE_API_KEY:
        progress_bar.progress(85, text="ğŸ” êµ¬ê¸€ ìƒì„¸ ê²€ìƒ‰ ì¤‘...")
        queries = [name] + [f"{name} {kw}" for kw in ["ì—…ì ", "Inventions", "Work"]]
        service = build("customsearch", "v1", developerKey=GOOGLE_API_KEY)
        for q in queries:
            try:
                res = service.cse().list(q=q, cx=GOOGLE_SEARCH_ENGINE_ID, searchType='image', num=COUNT_GOOGLE, safe='active').execute()
                if 'items' in res:
                    for i, item in enumerate(res['items']):
                        download_image(item['link'], folder_name, f"Google_{q}_{i}.jpg", source_list, visited_urls)
            except: pass

    # ë§ˆë¬´ë¦¬
    progress_bar.progress(100, text="ì™„ë£Œ!")
    
    # ì¶œì²˜ íŒŒì¼ ì €ì¥
    with open(os.path.join(folder_name, "00_ì¶œì²˜.txt"), "w", encoding="utf-8") as f:
        for item in source_list: f.write(f"{item}\n")
        
    return source_list

# ==========================================
# [í™”ë©´] Streamlit UI êµ¬ì„±
# ==========================================
def main():
    st.set_page_config(page_title="ì—­ì‚¬ ì¸ë¬¼ ì•„ì¹´ì´ë¸Œ", page_icon="ğŸ›ï¸")
    
    st.title("ğŸ›ï¸ ì—­ì‚¬ ì¸ë¬¼ ë§ˆìŠ¤í„° AI")
    st.markdown("ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ë©´ **ìœ„í‚¤, eë®¤ì§€ì—„, ë©”íŠ¸ë¡œí´ë¦¬íƒ„, êµ¬ê¸€**ì„ ëª¨ë‘ ê²€ìƒ‰í•˜ì—¬ ì •ë¦¬í•´ì¤ë‹ˆë‹¤.")

    with st.form("search_form"):
        name = st.text_input("ì°¾ì„ ì¸ë¬¼ ì´ë¦„ (ì˜ˆ: ì„¸ì¢…ëŒ€ì™•, ë°˜ ê³ í)", "")
        
        col1, col2 = st.columns(2)
        with col1:
            use_met = st.checkbox("ğŸ›ï¸ ë©”íŠ¸ë¡œí´ë¦¬íƒ„ ê²€ìƒ‰ (ì˜ˆìˆ ê°€/ê³ ëŒ€)", value=False)
        with col2:
            use_google = st.checkbox("ğŸ” êµ¬ê¸€ ê²€ìƒ‰ ì¶”ê°€ (ì—…ì  í¬í•¨)", value=True)
            
        submitted = st.form_submit_button("ğŸ” ê²€ìƒ‰ ì‹œì‘ (Start)")

    if submitted and name:
        folder_name = "temp_result" # ì„ì‹œ í´ë”
        create_temp_folder(folder_name)
        
        progress_bar = st.progress(0, text="ì¤€ë¹„ ì¤‘...")
        
        # ê²€ìƒ‰ ì‹¤í–‰!
        source_list = run_search_logic(name, folder_name, use_met, use_google, progress_bar)
        
        st.success(f"ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(source_list)}ê°œì˜ ìë£Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # 1. ê°¤ëŸ¬ë¦¬ ë³´ì—¬ì£¼ê¸°
        st.subheader("ğŸ–¼ï¸ ìˆ˜ì§‘ëœ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°")
        images = [f for f in os.listdir(folder_name) if f.endswith(('.jpg', '.png'))]
        if images:
            st.image([os.path.join(folder_name, img) for img in images[:9]], width=100, caption=images[:9])
            if len(images) > 9:
                st.info(f"...ì™¸ {len(images)-9}ì¥ ë” ìˆìŒ")

        # 2. ì••ì¶• íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (í°ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê¸°ëŠ¥)
        shutil.make_archive(f"{name}_ìë£Œëª¨ìŒ", 'zip', folder_name)
        
        with open(f"{name}_ìë£Œëª¨ìŒ.zip", "rb") as fp:
            st.download_button(
                label="ğŸ“¦ ì „ì²´ ìë£Œ ë‹¤ìš´ë¡œë“œ (ZIP)",
                data=fp,
                file_name=f"{name}_ìë£Œëª¨ìŒ.zip",
                mime="application/zip"
            )

if __name__ == "__main__":
    main()